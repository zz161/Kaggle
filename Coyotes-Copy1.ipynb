{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# loading training data\n",
    "x_train = []\n",
    "for i in range(1500):\n",
    "    im = Image.open(cwd + '/training/{}.tif'.format(i))\n",
    "    x_train.append(np.asarray(im))\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = np.genfromtxt(cwd + '/labels_training.csv', delimiter=',', skip_header = 1)\n",
    "y_train = y_train.T[1]\n",
    "\n",
    "# loading testing data\n",
    "x_test = []\n",
    "for i in range(1500,2058):\n",
    "    im = Image.open(cwd + '/testing/{}.tif'.format(i))\n",
    "    x_test.append(np.asarray(im))\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhuangdiezhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuangdiezhou/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "# Download model weights\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "# Re-structure model\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024, activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024, activation='relu')(x) #dense layer 2\n",
    "x=Dense(512, activation='relu')(x) #dense layer 3\n",
    "preds=Dense(1, activation='sigmoid')(x) #final layer with softmax activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)\n",
    "'''\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhuangdiezhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/zhuangdiezhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/zhuangdiezhou/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "1200/1200 [==============================] - 64s 53ms/step - loss: 1.3692 - acc: 0.7417 - f1: nan - auc: 0.6654 - val_loss: 1.4887 - val_acc: 0.8400 - val_f1: 0.6791 - val_auc: 0.8031\n",
      "Epoch 2/30\n",
      "1200/1200 [==============================] - 59s 49ms/step - loss: 0.1817 - acc: 0.9592 - f1: 0.9357 - auc: 0.8668 - val_loss: 0.3190 - val_acc: 0.8833 - val_f1: 0.8505 - val_auc: 0.9060\n",
      "Epoch 3/30\n",
      "1200/1200 [==============================] - 59s 49ms/step - loss: 0.0668 - acc: 0.9867 - f1: 0.9793 - auc: 0.9281 - val_loss: 0.5834 - val_acc: 0.9333 - val_f1: 0.8953 - val_auc: 0.9428\n",
      "Epoch 4/30\n",
      "1200/1200 [==============================] - 87s 72ms/step - loss: 0.0797 - acc: 0.9842 - f1: 0.9754 - auc: 0.9518 - val_loss: 4.0272 - val_acc: 0.7267 - val_f1: 0.3825 - val_auc: 0.9478\n",
      "Epoch 5/30\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 0.1396 - acc: 0.9642 - f1: 0.9434 - auc: 0.9452 - val_loss: 1.3095 - val_acc: 0.9167 - val_f1: 0.8640 - val_auc: 0.9482\n",
      "Epoch 6/30\n",
      "1200/1200 [==============================] - 81s 67ms/step - loss: 0.0779 - acc: 0.9808 - f1: 0.9700 - auc: 0.9511 - val_loss: 1.3607 - val_acc: 0.9233 - val_f1: 0.8727 - val_auc: 0.9540\n",
      "Epoch 7/30\n",
      "1200/1200 [==============================] - 99s 83ms/step - loss: 0.0425 - acc: 0.9900 - f1: 0.9825 - auc: 0.9568 - val_loss: 0.6661 - val_acc: 0.9533 - val_f1: 0.9255 - val_auc: 0.9599\n",
      "Epoch 8/30\n",
      "1200/1200 [==============================] - 68s 56ms/step - loss: 0.0289 - acc: 0.9950 - f1: 0.9920 - auc: 0.9627 - val_loss: 1.0288 - val_acc: 0.9067 - val_f1: 0.8497 - val_auc: 0.9643\n",
      "Epoch 9/30\n",
      "1200/1200 [==============================] - 52s 43ms/step - loss: 0.0294 - acc: 0.9933 - f1: 0.9885 - auc: 0.9657 - val_loss: 0.2928 - val_acc: 0.9700 - val_f1: 0.9534 - val_auc: 0.9678\n",
      "Epoch 10/30\n",
      "1200/1200 [==============================] - 51s 43ms/step - loss: 0.0264 - acc: 0.9942 - f1: 0.9896 - auc: 0.9697 - val_loss: 2.6876 - val_acc: 0.8867 - val_f1: 0.7963 - val_auc: 0.9693\n",
      "Epoch 11/30\n",
      "1200/1200 [==============================] - 54s 45ms/step - loss: 0.0356 - acc: 0.9908 - f1: 0.9867 - auc: 0.9697 - val_loss: 1.2810 - val_acc: 0.9300 - val_f1: 0.8903 - val_auc: 0.9705\n",
      "Epoch 12/30\n",
      "1200/1200 [==============================] - 63s 52ms/step - loss: 0.0191 - acc: 0.9950 - f1: 0.9920 - auc: 0.9714 - val_loss: 1.4962 - val_acc: 0.9333 - val_f1: 0.8942 - val_auc: 0.9719\n",
      "Epoch 13/30\n",
      "1200/1200 [==============================] - 55s 45ms/step - loss: 0.1293 - acc: 0.9700 - f1: 0.9529 - auc: 0.9724 - val_loss: 0.7524 - val_acc: 0.9500 - val_f1: 0.9213 - val_auc: 0.9726\n",
      "Epoch 14/30\n",
      "1200/1200 [==============================] - 70s 59ms/step - loss: 0.0394 - acc: 0.9883 - f1: 0.9794 - auc: 0.9733 - val_loss: 1.2439 - val_acc: 0.9367 - val_f1: 0.8995 - val_auc: 0.9737\n",
      "Epoch 15/30\n",
      "1200/1200 [==============================] - 86s 72ms/step - loss: 0.0134 - acc: 0.9933 - f1: 0.9889 - auc: 0.9742 - val_loss: 0.7998 - val_acc: 0.9500 - val_f1: 0.9215 - val_auc: 0.9748\n",
      "Epoch 16/30\n",
      "1200/1200 [==============================] - 53s 44ms/step - loss: 0.0057 - acc: 0.9992 - f1: 0.9992 - auc: 0.9754 - val_loss: 0.5206 - val_acc: 0.9667 - val_f1: 0.9507 - val_auc: 0.9761\n",
      "Epoch 17/30\n",
      "1200/1200 [==============================] - 70s 58ms/step - loss: 0.0080 - acc: 0.9967 - f1: 0.9927 - auc: 0.9768 - val_loss: 0.6083 - val_acc: 0.9333 - val_f1: 0.9131 - val_auc: 0.9772\n",
      "Epoch 18/30\n",
      "1200/1200 [==============================] - 69s 58ms/step - loss: 0.0188 - acc: 0.9975 - f1: 0.9961 - auc: 0.9777 - val_loss: 0.4546 - val_acc: 0.9267 - val_f1: 0.9037 - val_auc: 0.9782\n",
      "Epoch 19/30\n",
      "1200/1200 [==============================] - 65s 54ms/step - loss: 0.0128 - acc: 0.9975 - f1: 0.9957 - auc: 0.9787 - val_loss: 0.4042 - val_acc: 0.9533 - val_f1: 0.9359 - val_auc: 0.9792\n",
      "Epoch 20/30\n",
      "1200/1200 [==============================] - 58s 48ms/step - loss: 0.0647 - acc: 0.9842 - f1: 0.9731 - auc: 0.9794 - val_loss: 0.9077 - val_acc: 0.9467 - val_f1: 0.9202 - val_auc: 0.9796\n",
      "Epoch 21/30\n",
      "1200/1200 [==============================] - 56s 47ms/step - loss: 0.0053 - acc: 0.9992 - f1: 0.9980 - auc: 0.9799 - val_loss: 0.6389 - val_acc: 0.9600 - val_f1: 0.9423 - val_auc: 0.9803\n",
      "Epoch 22/30\n",
      "1200/1200 [==============================] - 55s 46ms/step - loss: 0.0123 - acc: 0.9967 - f1: 0.9961 - auc: 0.9807 - val_loss: 0.6294 - val_acc: 0.9567 - val_f1: 0.9359 - val_auc: 0.9810\n",
      "Epoch 23/30\n",
      "1200/1200 [==============================] - 54s 45ms/step - loss: 0.0105 - acc: 0.9975 - f1: 0.9952 - auc: 0.9813 - val_loss: 0.8193 - val_acc: 0.9433 - val_f1: 0.9172 - val_auc: 0.9816\n",
      "Epoch 24/30\n",
      "1200/1200 [==============================] - 54s 45ms/step - loss: 3.6278e-04 - acc: 1.0000 - f1: 1.0000 - auc: 0.9818 - val_loss: 0.6676 - val_acc: 0.9567 - val_f1: 0.9386 - val_auc: 0.9821\n",
      "Epoch 25/30\n",
      "1200/1200 [==============================] - 55s 45ms/step - loss: 0.0016 - acc: 0.9992 - f1: 0.9982 - auc: 0.9823 - val_loss: 0.5055 - val_acc: 0.9667 - val_f1: 0.9515 - val_auc: 0.9826\n",
      "Epoch 26/30\n",
      "1200/1200 [==============================] - 55s 46ms/step - loss: 0.0354 - acc: 0.9958 - f1: 0.9941 - auc: 0.9829 - val_loss: 0.5705 - val_acc: 0.9633 - val_f1: 0.9432 - val_auc: 0.9830\n",
      "Epoch 27/30\n",
      "1200/1200 [==============================] - 54s 45ms/step - loss: 0.0133 - acc: 0.9967 - f1: 0.9944 - auc: 0.9832 - val_loss: 0.4171 - val_acc: 0.9600 - val_f1: 0.9380 - val_auc: 0.9835\n",
      "Epoch 28/30\n",
      "1200/1200 [==============================] - 56s 47ms/step - loss: 0.0480 - acc: 0.9908 - f1: 0.9859 - auc: 0.9836 - val_loss: 0.5465 - val_acc: 0.9400 - val_f1: 0.9182 - val_auc: 0.9837\n",
      "Epoch 29/30\n",
      "1200/1200 [==============================] - 55s 45ms/step - loss: 0.0071 - acc: 0.9992 - f1: 0.9985 - auc: 0.9839 - val_loss: 0.4644 - val_acc: 0.9533 - val_f1: 0.9332 - val_auc: 0.9841\n",
      "Epoch 30/30\n",
      "1200/1200 [==============================] - 55s 46ms/step - loss: 0.0014 - acc: 1.0000 - f1: 1.0000 - auc: 0.9843 - val_loss: 0.3619 - val_acc: 0.9600 - val_f1: 0.9427 - val_auc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2c7fe4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 50\n",
    "epochs = 30\n",
    "\n",
    "# defining class weights by different number of classes\n",
    "class_weight={1: (len(y_train) - np.sum(y_train)) / np.sum(y_train),\n",
    "              0: 1}\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy',f1,auc])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          class_weight=class_weight,\n",
    "          verbose=1,\n",
    "          validation_split = 0.2)\n",
    "\n",
    "# The fitting process will take about 20~40 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and writting CSVs\n",
    "y = model.predict(x_test)\n",
    "df = pd.DataFrame({'id':np.arange(1500, 2058, 1),\n",
    "                  'score':y.T[0]})\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
